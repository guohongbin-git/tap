### **修订记录 (Change Log)**

| 版本 (Version) | 日期 (Date)   | 变更内容 (Change Description)       | 作者 (Author) | 审批人 (Approved By) |
| :---         | :---          | :---                                | :---          | :---                 |
| 2.3          | 2025年8月17日 | 根据新一轮QWEN评审意见进行精修，进一步提升清晰度和完整性。 | Gemini        | 郭宏斌               |
| 2.2          | 2025年8月17日 | 为三阶段计划中的每一个具体任务补充了明确的“检验标准”。 | Gemini        | (待审批)             |
| 2.1          | 2025年8月17日 | 根据QWEN AI的8条评审意见进行全面修订，提高了准确性、清晰度和可操作性。 | Gemini        | (待审批)             |
| 2.0          | 2025年8月16日 | 集成QWEN AI的建议，细化了三阶段计划的实施步骤，并增加了“技术债务与改进建议”章节。 | Gemini        | (待审批)             |
| 1.0          | 2025年8月16日 | 初版创建，基于对当前应用的全面审计。 | Gemini        | 郭宏斌               |

---
**版本**: 2.3
**状态**: 已批准

# **前端功能审计与三阶段增强计划 (DDR_09)**

## 1. 现状评估

通过对当前Web应用前端实现和项目设计文档的全面审计，我们确认了以下关键发现：
1.  **核心资产完备**: 后端系统已根据设计文档（DDR_01-DDR_08）完整实现了所有预期功能，包括数据生成、图构建、多种分区算法、评估模块和LLM集成。
2.  **前端实现滞后**: 前端应用目前仅实现了设计蓝图中的最小可行产品（MVP），远未暴露后端已实现的强大功能。例如，在“创建新实验”页面，目前已实现基本的数据源、算法、图构建和评估配置，但参数化和交互深度不足。
3.  **功能缺口显著**: 下文第2节将详细阐述6个关键模块/功能上的差距，亟待填补。

## 2. 功能差距详解

| 模块/功能 | 设计文档中的规划 (Should Be) | 当前前端的实现 (Is) | 差距说明 |
| :--- | :--- | :--- | :--- |
| **数据源配置** | 支持多种参数化的合成数据模型 (泊松分布、集群等)。 (`DDR_01`) | 仅支持配置“单元数”和“客户数”的简单模拟。 |无法利用后端强大的数据模拟能力。 |
| **图构建配置** | 可配置邻接关系 (Rook/Queen) 和权重计算方法。 (`DDR_03`) | 完全缺失。使用硬编码的默认值 (`queen`, `uniform`)。 | 用户无法控制图的构建方式，这是核心参数之一。 |
| **算法参数配置** | 支持为不同算法配置其各自所需的特定参数（例如，随机种子、初始化方法、迭代次数等）。 (`DDR_04`) | 仅支持所有算法通用的“分区数”配置。 |无法对算法进行微调和可复现的随机实验。 |
| **空间统计分析** | 提供独立的统计功能 (如雷普利K函数) 来分析数据空间模式。 (`DDR_02`) | **完全缺失**。 | 用户无法在实验前了解其输入数据的特征。 |
| **实验结果呈现** | 评估报告应格式化、可读，并呈现所有生成的可视化图表。 (`DDR_05`) | 直接以原始JSON格式展示评估报告，仅硬编码显示2张图。 | 结果难以解读，无法看到所有分析图表。 |
| **LLM智能交互** | 一个多Agent系统，支持对结果进行深度、可交互的问答式分析。 (`DDR_08`) | 仅有一个静态文本框，用于显示后端一次性生成的分析文本。 | **核心愿景未实现**。无法与AI进行交互和追问。 |

## 3. 三阶段增强计划（细化版）

为了系统性地弥合差距，我们将严格遵循并细化三阶段计划。

### **第一阶段：补全核心实验流程 (Phase 1: Complete the Core Experiment Workflow)**

**目标**：让“创建新实验”页面能完全控制后端的所有核心参数。这是最有价值的第一步，它能将后端的潜力直接释放给用户。

**具体实施步骤**：

1.  **任务1.1: 完善并激活“图构建”配置功能**
    *   **描述**: 虽然UI元素已存在，但需要确保其值能正确绑定到状态并随实验配置一同发送至后端。
    *   **前端变更**：
        *   在 `frontend/src/pages/NewExperimentPage.tsx` 中，于“数据源”和“算法配置”卡片之间插入一个名为 “3. 图构建配置” 的新卡片。
        *   在卡片内添加两个 `FormControl` 和 `Select` 组件：
            *   邻接方法: 选项为 `queen` (默认), `rook`。
            *   权重方法: 选项为 `uniform` (默认)。(注: 后端 `WeightingMethod` 枚举当前仅支持 `uniform`。)
    *   **状态管理**：
        *   为新增的下拉菜单绑定 `onChange` 事件处理器，确保其值能正确更新到 `formState.graph_builder_config` 中。
    *   **数据交互**：
        *   确保在调用 `/experiments/run` API 时，`formState` 中完整的 `graph_builder_config` 能被正确序列化并发送到后端。
    *   **检验标准 (Acceptance Criteria)**:
        *   **UI**: “图构建配置”卡片及内部的“邻接方法”、“权重方法”下拉菜单可见。
        *   **状态**: 更改下拉菜单选项后，`formState.graph_builder_config` 的值会相应更新。
        *   **交互**: 点击“运行实验”按钮时，通过浏览器开发者工具的网络(Network)标签页，可以确认发往 `/experiments/run` 的请求体中包含了正确的 `graph_builder_config` 对象，例如 `{"contiguity_method": "rook", "weighting_method": "uniform"}`。

2.  **任务1.2: 实现“算法”特定参数配置**
    *   **前端变更**：
        *   在 `frontend/src/pages/NewExperimentPage.tsx` 的“算法配置”区域内，修改渲染逻辑。
        *   根据 `exp.partitioner_type` 的值，有条件地渲染额外的参数输入框。
        *   例如，当 `exp.partitioner_type` 为 `'random'` 时，在其“分区数量”输入框后方，动态显示一个带有标签 “随机种子 (seed)” 的 `TextField` 组件。
    *   **技术指引**: 建议采用一个映射对象，将 `partitioner_type` 映射到其对应的参数配置组件/渲染函数。例如，定义 `const ParameterComponents: Record<PartitionerType, React.FC<...>> = {...}`。该映射对象应至少包含 `'random'` 和 `'kmeans'` 的条目，分别对应渲染 `seed` 输入框的组件。
    *   **状态管理**：
        *   修改 `formState.partitioner_experiments` 中对应项的 `partitioner_config` 对象，使其能容纳特定算法的参数（如 `seed`）。
        *   为动态生成的输入框绑定 `onChange` 事件处理器，更新 `formState.partitioner_experiments[index].partitioner_config`。
    *   **数据交互**：
        *   确保在调用 `/experiments/run` API 时，`formState.partitioner_experiments` 中每个实验配置的 `partitioner_config`（包含通用参数和特定参数）能被正确序列化并发送到后端。
    *   **检验标准 (Acceptance Criteria)**:
        *   **UI**: 当在算法下拉菜单中选择“random”或“kmeans”时，一个标记为“随机种子 (seed)”的输入框出现。选择其他算法时，该输入框不出现。
        *   **状态**: 在“随机种子”输入框中输入数字（如 `42`）后，`formState.partitioner_experiments` 中对应实验的 `partitioner_config` 对象会更新，例如变为 `{"num_partitions": 10, "seed": 42}`。
        *   **交互**: 运行实验的API请求体中，对应实验的 `partitioner_config` 包含了完整的、正确的参数。

### **第二阶段：丰富化数据分析与结果呈现 (Phase 2: Enrich Data Analysis & Result Presentation)**

**目标**：提供实验前的数据洞察，并让实验结果更具可读性和洞察力。

**具体实施步骤**：

1.  **任务2.1: 激活“空间统计分析”功能**
    *   **前端变更**：
        *   在 `frontend/src/pages/DataManagementPage.tsx` 中，为每个已处理的数据集列表项，增加一个 “分析” 按钮。
        *   点击按钮后，应弹出一个 `Dialog` 或 `Modal` 组件。
    *   **API对接**：
        *   在 `frontend/src/services/api.ts` 中，新增一个用于调用空间统计分析的函数，例如 `analyzeKFunction(datasetName: string)`，该函数应向一个新后端端点发起请求。
        *   后端需要提供一个符合RESTful风格的API端点（例如 `GET /datasets/{dataset_name}/analysis/k_function`），用于接收数据集名称，调用 `src.spatial_stats.point_pattern_analysis.analyze_k_function`，并将结果（`r`, `k_values`, `k_expected`）返回。
    *   **可视化**：
        *   在弹出的对话框中，使用 `recharts` 或类似的图表库，将从API获取的K函数分析结果绘制成折线图，清晰展示观测值、期望值和置信区间，帮助用户判断数据的空间分布模式。
    *   **检验标准 (Acceptance Criteria)**:
        *   **UI**: 在数据管理页面，每个数据集项旁边都有一个“分析”按钮。点击后，会弹出一个模态框。
        *   **交互**: 模态框弹出时，会显示加载指示器。加载完成后，框内会显示一个使用 `recharts` 绘制的K函数图表。如果API调用失败，会显示一条错误消息。
        *   **API**: 点击“分析”按钮会触发一个向 `GET /datasets/.../analysis/k_function` 端点的网络请求。

2.  **任务2.2: 优化“实验结果”页面**
    *   **前端变更**：
        1.  **优化JSON展示**：
            *   替换 `ResultsPage.tsx` 中用于展示 `results.evaluation_reports` 的 `<pre>` 标签。
            *   使用 Material-UI 的 `Accordion`, `Table` 或 `Card` 组件，将评估报告JSON中的关键指标（如平衡性、紧凑性、连通性评分）进行格式化解析和展示，使其结构清晰、易于阅读。
        2.  **动态加载可视化图表**：
            *   修改 `ResultsPage.tsx` 中的渲染逻辑。
            *   不再硬编码展示 `partition_map.png` 和 `partition_balance_distribution.png`。
            *   向后端发起请求（例如 `GET /experiments/results/{experimentId}/visualizations`），获取该次实验生成的所有可视化资源的相关信息（例如文件名列表或包含路径、类型等元数据的对象）。
            *   遍历返回的资源列表，动态生成 `CardMedia` 组件来展示每一张图片，并根据文件名推断其内容（如通过文件名包含“balance”来判断是平衡性图表）。
    *   **检验标准 (Acceptance Criteria)**:
        *   **UI (报告)**: 实验结果页的评估报告部分，不再是纯JSON文本，而是由 `Accordion` 或 `Table` 等组件构成的格式化视图。
        *   **UI (图表)**: 页面上展示的可视化图表数量与后端返回的数量一致，不再仅限于2张硬编码的图片。
        *   **API**: 页面加载时，会触发一个向 `GET /experiments/results/.../visualizations` 端点的网络请求。

### **第三阶段：激活LLM智能交互 (Phase 3: Activate LLM Interactive Intelligence)**

**目标**：实现本项目的终极目标——人机协同的智能分析。

**具体实施步骤**：

1.  **任务3.1: 实现交互式LLM分析**
    *   **前端变更**：
        *   将 `ResultsPage.tsx` 中的“智能分析”标签页内容，从一个静态的 `<Paper>` 容器，替换为一个聊天界面。
        *   使用 `TextField` 作为用户输入框，`Button` 作为发送按钮，并使用 `List` 或 `Box` 来展示聊天记录。
    *   **交互流程**：
        1.  **初始报告**：
            *   页面加载时，应在聊天区域显示一条‘正在生成初始分析...’的临时消息或加载动画。
            *   随后，调用后端API获取LLM生成的初始分析报告，并用其替换加载指示，作为第一条消息（系统消息）添加到聊天界面中。
        2.  **用户追问**：
            *   用户在输入框中输入问题（例如，“详细比较A算法和B算法在平衡性方面的表现”）并点击发送。
        3.  **后端处理**：
            *   前端向后端一个新的API端点（例如 `POST /experiments/results/{experimentId}/llm_chat`）发送请求。
            *   请求体应包含用户问题和当前实验的上下文（可通过实验ID在后端获取）。
            *   后端接收到请求后，将用户问题、实验上下文（MCP）一并交给 `OrchestrationAgent` 进行处理。
            *   `OrchestrationAgent` 根据问题动态生成执行计划，调用相应的 `FunctionalAgent` 或 `Tool`，并整合结果生成回答。
            *   后端将LLM生成的回答通过API返回给前端。
        4.  **前端显示**：
            *   前端接收到后端返回的问答内容，将其作为一条新的用户消息追加到聊天记录中。
        5.  **加载与错误状态管理**:
            *   **加载状态**: 发送请求时，输入框和按钮应禁用，并在按钮旁显示一个旋转图标或文本‘...’。
            *   **错误处理**: 若请求失败（如网络错误、后端异常），应在聊天记录区域或输入框附近显示一条醒目的错误消息，并提供‘重试’按钮。
    *   **检验标准 (Acceptance Criteria)**:
        *   **UI**: “智能分析”标签页显示一个聊天窗口，包含聊天记录区、文本输入框和发送按钮。
        *   **交互 (加载)**: 页面加载时，聊天区域首先显示加载指示。加载完成后，初始分析报告自动出现在聊天记录中，替换掉加载指示。
        *   **交互 (问答)**: 用户输入问题并点击发送后，该问题出现在聊天记录中。短暂的加载状态后（按钮禁用），LLM的回答也出现在聊天记录中。
        *   **API**: 发送问题会触发一个向 `POST /experiments/results/.../llm_chat` 端点的网络请求，请求体包含用户输入的内容。
        *   **交互 (错误处理)**: 如果API调用失败，聊天界面会显示错误提示和重试选项。

## 4. 技术债务与改进建议

除了上述功能增强外，还应注意以下技术层面的优化：
1.  **代码复用与组件化**: 对于重复出现的UI元素（如算法配置项、数据源配置项），应提取为可复用的React组件，提高代码维护性。
2.  **状态管理优化**: 随着功能的增加，考虑引入更强大的状态管理方案（如Redux Toolkit或Zustand）来管理复杂的应用状态。
3.  **类型安全**: 确保 `frontend/src/types/index.ts` 与后端 `src/common/schemas.py`保持严格同步，避免因类型不匹配导致的运行时错误。
4.  **API错误处理**: 完善前端对API调用错误的处理，提供友好的用户提示。
5.  **性能优化**: 对于大数据量的可视化图表和评估报告展示，考虑使用虚拟滚动、懒加载等技术优化性能。

## 5. 总结

严格遵循并深化本计划，是推动TAP项目前端从MVP走向完整、强大、用户友好的关键。通过系统性地实施上述改进措施，我们能够逐步解锁后端已实现的全部潜能，最终为用户提供一个功能完备、数据驱动、智能交互的先进领土划分分析平台。