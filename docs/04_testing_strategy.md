### **修订记录 (Change Log)**

| 版本 (Version) | 日期 (Date) | 变更内容 (Change Description) | 作者 (Author) | 审批人 (Approved By) |
| :--- | :--- | :--- | :--- | :--- |
| 1.1 | 2025年8月15日 | 根据QWEN AI建议，增加了测试数据管理、代码覆盖率目标和CI平台细节。 | Gemini | (待审批) |
| 1.0 | 2025年8月15日 | 初版创建，定义了项目的多层次测试策略和持续集成计划。 | Gemini | 郭宏斌 |

---
**版本**: 1.1
**状态**: 草案
**作者**: Gemini

---

# **测试策略文档 (DDR_04)**

## 1. 概述 (Overview)

本文档为“TAP工具箱”项目定义了全面的质量保证和测试策略。目标是建立一个自动化的、多层次的测试体系，以确保系统的准确性、稳定性和可维护性。

## 2. 测试原则

*   **测试金字塔 (Test Pyramid)**: 我们的测试将遵循标准的测试金字塔模型，拥有大量的单元测试、适量的集成测试和少量的端到端测试。
*   **自动化优先 (Automation-First)**: 所有可被自动化的测试，都必须被自动化，并集成到持续集成（CI）流程中。
*   **数据驱动 (Data-Centric)**: 测试的核心是数据。我们将使用小型的、确定性的、专门为测试设计的合成数据集来确保测试结果的稳定和可复现。

## 3. 测试数据管理 (Test Data Management)

*   **存储位置**: 所有用于自动化测试的合成数据集，都将以人类可读的格式（如CSV, JSON）存放在代码库的`tests/data/`目录下。
*   **版本控制**: 测试数据被视为代码的一部分，与代码一同接受版本控制（Git）。任何对测试数据的修改都必须遵循与代码变更相同的评审流程。
*   **命名规范**: 测试数据集应被描述性地命名，以清晰地反映其特征，例如`simple_5_clusters_data.csv`。

## 4. 测试层次与策略

我们将实施以下四个层次的自动化测试：

**4.1. 单元测试 (Unit Tests)**
*   **目的**: 验证最小的可测试代码单元（如单个函数或方法）的行为是否符合预期。
*   **工具**: `pytest`
*   **范围**:
    *   `common`模块中的所有工具函数。
    *   `evaluation`模块中每个评估指标的计算逻辑。
    *   `data_processing`模块中，独立的数据转换函数。
*   **位置**: `tests/unit/`

**4.2. 集成测试 (Integration Tests)**
*   **目的**: 确保不同模块之间的数据流和交互是正确无误的。
*   **工具**: `pytest`
*   **范围**:
    *   测试“数据生成器”的输出，是否能被“图构建器”正确地读取和处理。
    *   测试“图构建器”的输出，是否符合“算法核心层”统一接口的输入要求。
    *   测试“算法核心层”的_输出，是否能被“分析评估层”正确地解析和评估。
*   **位置**: `tests/integration/`

**4.3. 功能/端到端测试 (Functional / E2E Tests)**
*   **目的**: 模拟用户的真实使用场景，验证整个系统作为一个整体是否能按预期工作。
*   **工具**: `pytest` + `自动化调度中心`
*   **范围**:
    *   创建一个小型的、包含所有步骤的测试用例配置文件（如`test_e2e.yaml`）。
    *   通过`自动化调度中心`运行这个配置。
    *   测试脚本将断言（Assert）所有预期的输出文件（如日志、图片、结果数据）是否都已生成，以及其内容是否包含某些预期的关键信息。
*   **位置**: `tests/functional/`

**4.4. 视觉回归测试 (Visual Regression Tests)**
*   **目的**: 对于一个数据驱动的可视化项目，确保图表和地图的视觉呈现不会在代码更新后发生非预期的变化。
*   **工具**: `pytest-mpl` 或其他图像对比库。
*   **范围**:
    *   针对`visualization`模块中所有的静态绘图函数。
    *   测试流程：
        1.  首次运行时，为每个绘图函数生成一个“基准图像”（Baseline Image）并存入代码库。
        2.  后续测试运行时，生成新的“当前图像”。
        3.  用工具比对“当前图像”和“基准图像”的像素差异。如果差异超出阈值，则测试失败。
        4.  如果视觉变更是符合预期的，则由开发者手动更新基准图像。
*   **位置**: `tests/visual/`

## 5. 质量门禁 (Quality Gates)

*   **代码覆盖率**: 我们的目标是，核心业务逻辑的单元测试覆盖率不低于 **85%**。
*   **监控与报告**: 代码覆盖率报告将通过`pytest-cov`插件生成，并在每次CI运行时进行检查。任何导致总覆盖率低于阈值的代码合并请求（Pull Request）将被自动阻止。

## 6. 持续集成 (Continuous Integration, CI)

*   **平台**: 我们将使用 **GitHub Actions** 作为我们的CI/CD平台。
*   **工作流**: 工作流将在代码`push`或`pull_request`到主分支时自动触发，并执行以下核心步骤：
    1.  安装所有核心及开发依赖。
    2.  运行代码风格检查和Linter (`black`, `ruff`)。 
    3.  运行所有层级的自动化测试 (`pytest`)。
    4.  计算并上传代码覆盖率报告。
*   **规则**: 只有当所有CI步骤都成功通过时，代码才被允许合入主分支。